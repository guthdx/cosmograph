---
phase: 05-fastapi-backend
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - src/cosmograph/api/routes/extract.py
  - src/cosmograph/api/main.py
autonomous: true

must_haves:
  truths:
    - "Can upload file via POST /api/extract and get job_id"
    - "Can poll job status via GET /api/extract/{id}"
    - "Extraction runs in background, not blocking"
    - "LLM extraction requires llm_confirmed=true flag"
  artifacts:
    - path: "src/cosmograph/api/routes/extract.py"
      provides: "File upload and extraction endpoints"
      min_lines: 80
      contains: "@router.post"
    - path: "src/cosmograph/api/main.py"
      provides: "App with extract router included"
      contains: "extract"
  key_links:
    - from: "src/cosmograph/api/routes/extract.py"
      to: "src/cosmograph/services/extraction.py"
      via: "calls ExtractionService"
      pattern: "ExtractionService"
    - from: "src/cosmograph/api/routes/extract.py"
      to: "src/cosmograph/api/deps.py"
      via: "uses JobStore"
      pattern: "job_store"
---

<objective>
Implement extraction endpoints for file upload and job polling

Purpose: Create the core extraction API endpoints that accept file uploads, spawn background processing, and allow clients to poll for status. This is the primary API functionality that the frontend will use.

Output:
- POST /api/extract - upload files, start extraction job
- GET /api/extract/{job_id} - poll job status
- Background task processing with progress updates
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-fastapi-backend/05-RESEARCH.md
@.planning/phases/05-fastapi-backend/05-01-SUMMARY.md
@.planning/phases/05-fastapi-backend/05-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extraction routes module</name>
  <files>src/cosmograph/api/routes/extract.py</files>
  <action>
Create `routes/extract.py` with file upload and job management endpoints:

1. Imports:
   - tempfile, shutil, json from stdlib
   - Path from pathlib
   - APIRouter, UploadFile, File, Form, BackgroundTasks, HTTPException from fastapi
   - ExtractionService from services
   - JobStore, get_job_store from deps
   - Schemas from schemas
   - Logging for audit trail

2. Create router with prefix="/api"

3. POST /extract endpoint:
   ```python
   @router.post("/extract", response_model=JobResponse)
   async def create_extraction(
       files: list[UploadFile] = File(...),
       extractor: str = Form(default="auto"),
       title: str = Form(default="Knowledge Graph"),
       llm_confirmed: bool = Form(default=False),
       background_tasks: BackgroundTasks,
   ):
   ```
   - Validate files not empty (raise 400 if no files)
   - If extractor="llm" and not llm_confirmed, return 400 with message about requiring confirmation
   - Create temp directory: `tempfile.mkdtemp(prefix="cosmograph_")`
   - Save uploaded files to temp dir using shutil.copyfileobj (stream, not read all)
   - Create job via job_store.create_job(total=len(files))
   - Add background task: run_extraction(job_id, saved_files, extractor, title, temp_dir, llm_confirmed)
   - Return JobResponse immediately with job_id and status=pending

4. GET /extract/{job_id} endpoint:
   ```python
   @router.get("/extract/{job_id}", response_model=JobResponse)
   async def get_extraction_status(job_id: str):
   ```
   - Get job from store, raise 404 if not found
   - Return JobResponse with current status

5. run_extraction() background function (not async - runs in thread):
   ```python
   def run_extraction(job_id: str, files: list[Path], extractor: str, title: str, temp_dir: Path, llm_confirmed: bool):
   ```
   - Create ExtractionService
   - Define progress_callback that calls job_store.update_progress
   - Try:
     - Set interactive=False for LLM (already confirmed via API)
     - Call service.process_files() with progress_callback
     - Call service.generate_outputs()
     - Store graph.to_json() as result
     - Call job_store.complete_job()
   - Except Exception as e:
     - Log error
     - Call job_store.fail_job(job_id, str(e))
   - Finally:
     - Note: Don't clean temp_dir yet - needed for downloads (cleanup in later plan)

Key design points:
- Use Form() not Body() for multipart form data compatibility
- Stream files to disk, never await file.read() for large files
- Background task runs sync code (extractors are sync) - FastAPI handles threading
- LLM approval handled by requiring llm_confirmed=true (API equivalent of CLI --no-confirm)
  </action>
  <verify>
Run: `python -c "from cosmograph.api.routes.extract import router; print(f'{len(router.routes)} routes defined')"`
Run: `mypy src/cosmograph/api/routes/extract.py`
  </verify>
  <done>Extract routes module importable with POST /extract and GET /extract/{id}</done>
</task>

<task type="auto">
  <name>Task 2: Register extract router and test endpoints</name>
  <files>src/cosmograph/api/main.py</files>
  <action>
Update main.py to include the extract router:

1. Import: from .routes import extract
2. Add: app.include_router(extract.router)

Test the full flow manually:
1. Start server: uvicorn cosmograph.api.main:app --reload
2. Create a test file: echo "ARTICLE I - TEST\nSECTION 1. Content." > /tmp/test.txt
3. Upload: curl -X POST http://localhost:8000/api/extract -F "files=@/tmp/test.txt" -F "extractor=legal" -F "title=Test Graph"
4. Get job_id from response
5. Poll: curl http://localhost:8000/api/extract/{job_id}
6. Wait for status=completed
  </action>
  <verify>
Start uvicorn, run curl commands as above:
- POST returns job_id
- GET returns status (eventually completed or failed)
- No server crashes
  </verify>
  <done>Extraction endpoint accepts uploads and processes in background</done>
</task>

</tasks>

<verification>
- `curl -X POST .../api/extract -F "files=@test.txt"` returns job_id
- `curl .../api/extract/{job_id}` returns job status
- Job eventually reaches "completed" status
- LLM extraction without llm_confirmed=true returns 400
- Server does not block during extraction
- `mypy src/cosmograph/api/` clean
</verification>

<success_criteria>
- Can upload file via curl and get job_id
- Can poll job status until completion
- Background processing works (server remains responsive)
- LLM extraction requires explicit confirmation flag
- Error handling returns helpful messages
</success_criteria>

<output>
After completion, create `.planning/phases/05-fastapi-backend/05-03-SUMMARY.md`
</output>
